{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0f12f-410e-47fc-affb-2f0c5288c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from ast import literal_eval\n",
    "import nltk\n",
    "\n",
    "import statsmodels.formula.api as smf # A convenience interface for specifying models using formula strings and DataFrames. Canonically imported using import statsmodels.formula.api as smf\n",
    "\n",
    "# package for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as clrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91375f2-54c4-44df-b178-ba9b189f583e",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f47b29f-ba68-4f6f-99d9-2683a2711ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\laudi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('brown')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbba828-617c-419b-bbef-b5d3cb3a465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import os \n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48cf00f-a995-472f-8287-8c95fe683af7",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c111e9-3c3d-4ea7-91eb-ec1bbc736952",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FIND = re.compile(r\".*repository.\")\n",
    "rep_path = re.search(PATH_FIND,os.getcwd()).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc474813-007d-46b8-9ab6-0287961ef4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file = pd.read_csv(rep_path+\"1 csv\\\\patent_data_RAW.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7badfc7-6905-4505-ba10-ef39c5e820f4",
   "metadata": {},
   "source": [
    "#### Noun creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "646acfc6-19da-4f3d-a678-b83fd96b1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define useful data in the dataset\n",
    "patent_data = raw_file[[\"id\", \"issue_date\", \"abstract\", \"xi_real\", 'subsection_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cb14e-c565-41f2-911b-ce5d97fee599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining functions\n",
    "def extract_nouns(abstract):\n",
    "    blob=TextBlob(abstract)\n",
    "    nouns = list(blob.noun_phrases)\n",
    "    return nouns\n",
    "\n",
    "# Apply functions to the dataframe\n",
    "patent_data['extracted_nouns'] = patent_data['abstract'].apply(extract_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550cd5e0-eee3-4499-8a11-10082d3ee21e",
   "metadata": {},
   "source": [
    "#### Year creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf523cb0-d24f-49b3-8a0f-962853af5482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract years from the issue date\n",
    "patent_data['issue_year'] = patent_data['issue_date'].str.slice(6,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1387bf1-15e0-4021-b0eb-77bab3b9977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_data.to_csv(\"final_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b462e-8feb-4c17-854b-f3534426ec4d",
   "metadata": {},
   "source": [
    "#### Varible of reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59d370e-3003-426b-b2db-50641af91899",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of years\n",
    "years = sorted(list(set(patent_data['issue_year'])))\n",
    "\n",
    "#extract subsections\n",
    "patent_subsections = sorted(list(set(patent_data['subsection_id'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c9095a-e5c8-432b-9905-9dfd897c8523",
   "metadata": {},
   "source": [
    "## Extract most used nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165e3bbc-7293-4e2e-801e-215059dce6c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T21:41:34.268176Z",
     "start_time": "2022-05-22T21:15:03.918343Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_nouns_dict = {}\n",
    "for i in patent_subsections: \n",
    "    top_nouns_dict_by_year={} \n",
    "    for y in years:\n",
    "        combination=[]\n",
    "        for m in patent_data['extracted_nouns'][(patent_data['issue_year']==y) & (patent_data['subsection_id']==i)]:\n",
    "            for w in m: \n",
    "                combination.append(w)\n",
    "        top_nouns_dict_by_year[y] = combination\n",
    "    top_nouns_dict[i]= top_nouns_dict_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21015b-eced-4398-b5cf-86f0feee8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could clean a bit the results before proceeding\n",
    "# this because not all nouns are good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "583130a0-6cba-48a8-9aae-7a2d53413e00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T21:42:04.658587Z",
     "start_time": "2022-05-22T21:41:34.283214Z"
    }
   },
   "outputs": [],
   "source": [
    "def sort_extract(my_list, n = 10):\n",
    "    \"\"\"\n",
    "    my_list -> list. We pass all the found nouns for combination year subsectionID\n",
    "    n -> int. We decide the number of nouns \n",
    "    \"\"\"\n",
    "    \n",
    "    # Then we extract top n most repeated words\n",
    "    my_dict = {}\n",
    "    for x in my_list:\n",
    "        if x in my_dict.keys():\n",
    "            my_dict[x] += 1\n",
    "        else:\n",
    "            my_dict[x] = 1\n",
    "    sorted_dict = {key: value for (key, value) in sorted(my_dict.items(), key=lambda x: x[1], reverse=True)}\n",
    "    top_noun = list(sorted_dict)[:n]\n",
    "    return top_noun\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0e382-8fdc-4e3b-9f89-873af2711130",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in patent_subsections:\n",
    "    for y in years: \n",
    "        top_nouns_dict[i][y] = sort_extract(top_nouns_dict[i][y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cfb8c71-3c17-456e-8818-49f7862a7975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T21:42:04.908641Z",
     "start_time": "2022-05-22T21:42:04.664102Z"
    }
   },
   "outputs": [],
   "source": [
    "# export Dict\n",
    "with open('top_nouns_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(top_nouns_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e073b816adbb62516ef6a1fb0a012a532d644a48bac22b8bcc94c77b6ed60c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
