{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5779f999-3b18-4a28-b209-872ea948f263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laudi\\anaconda3\\envs\\work\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from ast import literal_eval\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "import statsmodels.formula.api as smf # A convenience interface for specifying models using formula strings and DataFrames. Canonically imported using import statsmodels.formula.api as smf\n",
    "\n",
    "# package for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.colors as clrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd681b5-e0ab-42d1-90eb-132771d8d9eb",
   "metadata": {},
   "source": [
    "# Generation GPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff2e6348-4684-44df-a96b-82372dafdf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2-xl', pad_token_id =tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c95189f2-daa6-4622-975b-74d879ba1324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs = tokenizer.encode(create_start_log(list_of_nouns), return_tensors ='pt')\n",
    "\n",
    "# outputs = model.generate(inputs, max_length=50, do_sample=True, temperature = 2.0 , top_k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5ce27b8d-7661-4509-88a9-cb41846b5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2:\n",
    "    def __init__(self,list_noun, tokenizer,model):\n",
    "        self.noun = list_noun\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.input = None \n",
    "        self.output = None \n",
    "        self.text = None \n",
    "        \n",
    "    def start(self, sequence):\n",
    "        sequence = \", \".join(self.noun)\n",
    "        start_log = \"create a patent with the following words: \"+ sequence + \".\\n the following patent\"\n",
    "        return start_log\n",
    "    \n",
    "    def set_encoding(self):\n",
    "        self.inputs = self.tokenizer.encode(self.start(self.noun), return_tensors ='pt')\n",
    "        \n",
    "    def set_output(self):\n",
    "        self.output = self.model.generate(self.inputs, max_length=100, num_beams=5,no_repeat_ngram_size =2, early_stopping=True)# ,do_sample=True, temperature = 2.0 , top_k=40)\n",
    "        \n",
    "    def get_decoding(self):\n",
    "        self.text = self.tokenizer.decode(self.output[0], skip_special_tokens = True, clean_up_tokenization_spaces = True )\n",
    "        return \".\".join(self.text)\n",
    "        print(self.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3b27e35d-9823-498c-a034-ffa240e75972",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_noun = [\"neighbor\",\"electricity\",\"son\",\"cat\",\"wash\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d5c7194-bf25-44e1-a264-b95b45b75169",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = GPT2(list_noun, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7abc249c-2cf1-409e-b7a2-e41d32ffc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.set_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4472fda8-7490-457a-9936-6970dac7b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.set_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "429d518a-f234-4b59-a626-e7fdf8f204ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create a patent with the following words: neighbor, electricity, son, cat, wash.\n",
      " the following patent was filed in the United States Patent and Trademark Office:\n",
      "Patent Number: US 8,569,874\n",
      "The patent is for a device that can be used to detect the presence of a cat in a room. The device consists of an infrared sensor that is mounted on a wall or ceiling. When the sensor detects the cat's presence, it sends a signal to a\n"
     ]
    }
   ],
   "source": [
    "a.get_decoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94fffe1-786a-4939-a568-9daa7be36f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
